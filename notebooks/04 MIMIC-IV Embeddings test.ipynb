{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Basic overview of generated embedding .pkl file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pickle(filepath: str):\n",
    "    \"\"\"Load a pickled object.\n",
    "\n",
    "    Args:\n",
    "        filepath (str): Path to pickle (.pkl) file.\n",
    "\n",
    "    Returns:\n",
    "        Any: Loaded object.\n",
    "    \"\"\"\n",
    "    with open(filepath, \"rb\") as f:\n",
    "        data = pickle.load(f)\n",
    "    return data\n",
    "\n",
    "def save_pickle(target: dict, filepath: str, fname: str = \"mm_feat.pkl\"):\n",
    "    \"\"\"Save a pickled object from a dictionary.\n",
    "\n",
    "    Args:\n",
    "        filepath (str): Path to pickle (.pkl) file.\n",
    "\n",
    "    Returns:\n",
    "        Any: Loaded object.\n",
    "    \"\"\"\n",
    "    with open(os.path.join(filepath, fname), \"wb\") as f:\n",
    "        pickle.dump(target, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get patient IDs from pkl file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_embs = load_pickle(\"../outputs/prep_data_us/mmfair_feat.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20130"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(pt_embs.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Replace EHR data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_old = load_pickle(\"../outputs/prep_old/prep_data/mmfair_feat.pkl\")\n",
    "embeddings = load_pickle(\"../outputs/prep_data_us/mmfair_feat.pkl\")\n",
    "cols = load_pickle(\"../outputs/prep_data_us/mmfair_cols.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99]\n",
      "['gender_F', 'race_group_Hispanic_Latino', 'race_group_Black', 'race_group_White', 'race_group_Asian', 'race_group_Other', 'marital_status_Married', 'marital_status_Single', 'marital_status_Widowed', 'marital_status_Divorced', 'insurance_Medicare', 'insurance_Medicaid', 'insurance_Private', 'insurance_Other']\n"
     ]
    }
   ],
   "source": [
    "indices = [cols['static_cols'].index(col) for col in cols['static_cols'][-14:]]\n",
    "print(indices)\n",
    "print([cols['static_cols'][i] for i in indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20130 20596\n"
     ]
    }
   ],
   "source": [
    "print(len(embeddings.keys()), len(emb_old.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20130 20596\n",
      "0\n",
      "466\n"
     ]
    }
   ],
   "source": [
    "print(len(embeddings.keys()), len(emb_old.keys()))\n",
    "### Get keys in embeddings but not in embeddings_old\n",
    "keys = set(embeddings.keys()) - set(emb_old.keys())\n",
    "print(len(keys))\n",
    "### Get keys in embeddings_old but not in embeddings\n",
    "keys = set(emb_old.keys()) - set(embeddings.keys())\n",
    "print(len(keys))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 54.71428571,  88.        ,  98.14285714,  18.14285714,\n",
       "         95.57142857,  27.34285714],\n",
       "       [ 48.        ,  97.66666667,  98.        ,  17.33333333,\n",
       "         86.        ,  65.43333333],\n",
       "       [ 49.5       ,  96.        ,  99.75      ,  18.5       ,\n",
       "         87.5       ,  -1.        ],\n",
       "       [ 55.2       , 104.        ,  99.4       ,  18.4       ,\n",
       "         98.4       ,  19.02      ],\n",
       "       [ 43.75      ,  79.        ,  74.5       ,  14.5       ,\n",
       "         73.        ,  73.1       ]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_old[10296921]['dynamic_0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 54.71428571,  88.        ,  98.14285714,  18.14285714,\n",
       "         95.57142857,  98.2       ],\n",
       "       [ 48.        ,  97.66666667,  98.        ,  17.33333333,\n",
       "         86.        ,  98.65      ],\n",
       "       [ 49.5       ,  96.        ,  99.75      ,  18.5       ,\n",
       "         87.5       ,  98.65      ],\n",
       "       [ 55.2       , 104.        ,  99.4       ,  18.4       ,\n",
       "         98.4       ,  99.1       ],\n",
       "       [ 58.66666667, 105.66666667,  99.66666667,  19.66666667,\n",
       "         97.66666667,  97.8       ]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings[10296921]['dynamic_0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pt_key in embeddings.keys():\n",
    "    embeddings[pt_key]['notes'] = emb_old[pt_key]['notes']\n",
    "    #embeddings[pt_key]['static'] = np.array(embeddings[pt_key]['static']).reshape(1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Correct and export the embeddings\n",
    "save_pickle(embeddings, \"../outputs/prep_data_us\", \"mmfair_feat.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test SHAP values vs embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = load_pickle(\"../outputs/prep_data/mmfair_feat.pkl\")\n",
    "#emb_old = load_pickle(\"../outputs/prev_data/mmfair_feat.pkl\")\n",
    "cols = load_pickle(\"../outputs/prep_data/mmfair_cols.pkl\")\n",
    "test_ids = (pl.read_csv(os.path.join(\"../outputs/prep_data/testing_ids_ext_stay_7.csv\"))\n",
    "        .select(\"subject_id\")\n",
    "        .to_numpy()\n",
    "        .flatten()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_embeddings = load_pickle(\"../outputs/explanations/ext_stay_7_concat_static_timeseries_notes/shap_ext_stay_7_concat_static_timeseries_notes.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SHAP values inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Tabluar data\n",
    "for i in range(shap_embeddings['batch_1']['static'].shape[2]):\n",
    "    print(f\"{cols['static_cols'][i]} -> SHAP {shap_embeddings['batch_0']['static'][9][0][i]}; Actual {embeddings[test_ids[9]]['static'][0][i]}\")\n",
    "\n",
    "print(embeddings[test_ids[1]]['static'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare embedding keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(embeddings.keys()), len(emb_old.keys()))\n",
    "### Get keys in embeddings but not in embeddings_old\n",
    "keys = set(embeddings.keys()) - set(emb_old.keys())\n",
    "print(len(keys))\n",
    "### Get keys in embeddings_old but not in embeddings\n",
    "keys = set(emb_old.keys()) - set(embeddings.keys())\n",
    "print(len(keys))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "risk_dict = load_pickle(\"..\\outputs\\evaluation\\ext_stay_7_concat_static_timeseries\\pf_ext_stay_7_concat_static_timeseries.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fair_dict = load_pickle(\"../outputs/fairness/ext_stay_7_None_timeseries/pf_ext_stay_7_None_timeseries.pkl\")\n",
    "fair_dict_cst = load_pickle(\"../outputs/fairness/ext_stay_7_concat_static_timeseries/pf_ext_stay_7_concat_static_timeseries.pkl\")\n",
    "fair_dict_cstn = load_pickle(\"../outputs/fairness/ext_stay_7_concat_static_timeseries_notes/pf_ext_stay_7_concat_static_timeseries_notes.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fair_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Select the keys that start with fair_\n",
    "fair_keys = [key for key in fair_dict.keys() if key.startswith(\"fair_\")]\n",
    "### Select items from the dictionary that start with fair_\n",
    "fair_dict_f = {key: fair_dict[key] for key in fair_keys}\n",
    "fair_dict_cstf = {key: fair_dict_cst[key] for key in fair_keys}\n",
    "fair_dict_cstnf = {key: fair_dict_cstn[key] for key in fair_keys}\n",
    "### Display values within the keys\n",
    "fair_df = pd.concat([pd.DataFrame(fair_dict_f), pd.DataFrame(fair_dict_cstf), pd.DataFrame(fair_dict_cstnf)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fair_df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(risk_dict['risk_quantile']), len(risk_dict['y_prob']), len(risk_dict['test_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "risk_dict['yd_idx']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recode some of the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(\"../outputs/processed_data\", \"mmfair_feat.pkl\"), \"wb\") as f:\n",
    "        pickle.dump(embeddings, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extr_list = []\n",
    "for item in embeddings[id_val]['notes']:\n",
    "    extr_list.append(item[1])\n",
    "print(extr_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test training IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_hosp_death = pd.read_csv('../outputs/prep_data/training_ids_in_hosp_death.csv')\n",
    "val_hosp_death = pd.read_csv('../outputs/prep_data/validation_ids_in_hosp_death.csv')\n",
    "test_hosp_death = pd.read_csv('../outputs/prep_data/testing_ids_in_hosp_death.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_icu = pd.read_csv('../outputs/prep_data/training_ids_icu_admission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlap = set(train_icu['subject_id']).intersection(set(train_hosp_death['subject_id']))\n",
    "print(len(overlap))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_ids = list(embeddings.keys())\n",
    "overlap = set(emb_ids).intersection(set(train_hosp_death['subject_id']))\n",
    "overlapv = set(emb_ids).intersection(set(val_hosp_death['subject_id']))\n",
    "overlapt = set(emb_ids).intersection(set(test_hosp_death['subject_id']))\n",
    "print(len(overlap), len(overlapv), len(overlapt), len(train_hosp_death), len(embeddings.keys()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.10.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
